## Capacity - overfitting and underfitting

A model's capacity refers to the size and complexity of the patterns it is able to learn.

If your network is underfitting the data, you should try increasing its capacity.
You can increase the capacity of a network either by making it wider (more units to existing layers) or by making it deeper (adding more layers). 
Wider networks have an easier time learning more linear relationships, while deeper networks prefer more nonlinear ones.

```
model = keras.Sequential([
    layers.Dense(16, activation='relu'),
    layers.Dense(1),
])

wider = keras.Sequential([
    layers.Dense(32, activation='relu'),
    layers.Dense(1),
])

deeper = keras.Sequential([
    layers.Dense(16, activation='relu'),
    layers.Dense(16, activation='relu'),
    layers.Dense(1),
])
```

## Early Stops

Training with early stopping also means we're in less danger of stopping the training too early, before the network has finished learning signal. 

Early stopping can also prevent underfitting from not training long enough.
Just set your training epochs to some large number (more than you'll need), and early stopping will take care of the rest.

```
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=20, # how many epochs to wait before stopping
    restore_best_weights=True,
)
```

These parameters say: "If there hasn't been at least an improvement of 0.001 in the validation loss over the previous 20 epochs, then stop the training and keep the best model you found."
