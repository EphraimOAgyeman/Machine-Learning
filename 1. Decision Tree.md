## AI Imports

> `Import data`  - import pandas as pd    -    df = pd.read_csv("csvName")


> `Splitting data` - import sklearn.model_selection import train_test_split    -   train_X, val_X, train_Y, val_y = train_test_split(random_state=1)


>  `DecisionTree model` - from sklearn.tree import DecisionTreeRegressor   -    model = DecisionTreeRegressor(random_state=1)  - model.fit(train_X, train_Y)  -  val_predictions = model.predict(val_X)


>  `MeanAbsiluteError` - from sklearn.metrics import mean_absolute_error   -  print(val_Y, val_predictions)


# Decision Tree - without splitting Data and validation
`Step 1 - Load your prepared data`
```
import pandas as pd

df = pd.read_csv('datasetName.csv')
df.head()
```
 
`Step 2 - Specify your prediction target - Y`
```
Y = df.columnName
```
 
`Step 3 - Specify your prediction features - X`
```
# Starts by grouping all needed columns in a list

features_list = ['columnName1','columnName2','columnName3','columnName4','columnNamen']
X = df[features_list]

print(X.head())
```

`Step 4 - Specify your model and fit/train it`
```
from sklearn.tree import DecisionTreeRegressor

#For model reproducibility, set a numeric value for random_state when specifying the model
model = DecisionTreeRegressor(random_state=1)

model.fit(X,Y)
```

`Step 5 - Make predictions`
```
print(X.head(7))
model.predict(X.head(7))
```


`Step 6 - Make predictions`
```
print(X.head(7))
model.predict(X.head(7))
```


# Decision Tree - Accuracy check with Mean Absolute Error (MAE)

> You should have imported your data and have the `X` and `Y` setted

```
from sklearn.tree import DecisionTreeRegressor

# Define model
model = DecisionTreeRegressor()

# Fit model
model.fit(X, Y)
```

> Accuracy with MAE

```
from sklearn.metrics import mean_absolute_error

predicted_home_prices = model.predict(X)
mean_absolute_error(Y, predicted_home_prices)
```


# Decision Tree - Validation with Mean Absolute Error (MAE)

```
from sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.

train_X, val_X, train_Y, val_Y = train_test_split(X, Y, random_state = 0)

# Define model
melbourne_model = DecisionTreeRegressor()

# Fit model
melbourne_model.fit(train_X, train_Y)

# get predicted prices on validation data
val_predictions = melbourne_model.predict(val_X)

print(mean_absolute_error(val_Y, val_predictions))
```


# Decision tree with the best tree size
Step 1 - compare MAE scores from different values for max_leaf_nodes, starting with this function:

```
from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor

def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
    model.fit(train_X, train_y)
    preds_val = model.predict(val_X)
    mae = mean_absolute_error(val_y, preds_val)
    return(mae)
```

Step 2 - Start the actual process

```
# Data Loading Code Runs At This Point
import pandas as pd
    
# Load data
melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
melbourne_data = pd.read_csv(melbourne_file_path) 
# Filter rows with missing values
filtered_melbourne_data = melbourne_data.dropna(axis=0)
# Choose target and features
y = filtered_melbourne_data.Price
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 
                        'YearBuilt', 'Lattitude', 'Longtitude']
X = filtered_melbourne_data[melbourne_features]

from sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)
```

Step 3A - use a for-loop to compare the accuracy of models built with different values for max_leaf_nodes.


```
# compare MAE with differing values of max_leaf_nodes
for max_leaf_nodes in [5, 50, 500, 5000]:
    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))
```

Step 3B 
```
candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]
# Write loop to find the ideal tree size from candidate_max_leaf_nodes
scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}

# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)
best_tree_size = min(scores, key=scores.get)

# Check your answer
step_1.check()
```


Step 4- when the best max_leaf_node has been found, create a final model

```
# Fill in argument to make optimal size and uncomment
final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)

# fit the final model and uncomment the next two lines
final_model.fit(X, y)


# Check your answer
step_2.check()
```
